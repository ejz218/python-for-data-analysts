{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Putting It All Together - The Complete Data Analysis Workflow\n",
    "\n",
    "---\n",
    "\n",
    "## The CRAWL â†’ WALK â†’ RUN Framework\n",
    "\n",
    "This textbook uses a structured approach to learning Python while developing effective AI collaboration skills. Each chapter follows three distinct phases:\n",
    "\n",
    "| Mode | Icon | AI Policy | Purpose |\n",
    "|------|------|-----------|--------|\n",
    "| **CRAWL** | ðŸ› | No AI assistance | Build foundational skills you can demonstrate independently |\n",
    "| **WALK** | ðŸš¶ | AI for understanding only | Use AI to explain concepts and errors, but write your own code |\n",
    "| **RUN** | ðŸš€ | Full AI collaboration | Partner with AI on complex tasks while documenting your process |\n",
    "\n",
    "**This Chapter is Different:** You've built eight chapters of foundational skills. Chapter 9 is primarily a RUN chapter where you'll apply everything you've learned to a complete, realistic data analysis project. However, we'll start with a CRAWL review to ensure you're ready for the final exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š The Professional Data Analysis Workflow\n",
    "\n",
    "In the real world, data analysis follows a predictable workflow. You've learned the pieces; now you'll see how they connect:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    THE DATA ANALYSIS WORKFLOW                               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  1. DEFINE THE QUESTION          What problem are we solving?              â”‚\n",
    "â”‚         â†“                        What decisions will this inform?           â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  2. ACQUIRE DATA                 Where does the data come from?            â”‚\n",
    "â”‚         â†“                        Chapter 5: File I/O                        â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  3. CLEAN & VALIDATE             Is the data trustworthy?                  â”‚\n",
    "â”‚         â†“                        Chapter 5: Exceptions, Chapter 7: Pandas  â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  4. EXPLORE                      What patterns exist?                       â”‚\n",
    "â”‚         â†“                        Chapter 6: NumPy, Chapter 7: Pandas        â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  5. ANALYZE                      What do the patterns mean?                â”‚\n",
    "â”‚         â†“                        Chapters 6-7: Statistical analysis         â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  6. VISUALIZE                    How do we communicate findings?           â”‚\n",
    "â”‚         â†“                        Chapter 8: Matplotlib & Seaborn            â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â”‚  7. COMMUNICATE                  What actions should stakeholders take?    â”‚\n",
    "â”‚                                  This chapter: Telling the story            â”‚\n",
    "â”‚                                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Professional Reality:** Steps 2-4 typically consume 60-80% of your time. The analysis itself is often the easy part once you have clean, understood data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will:\n",
    "\n",
    "- ðŸ› Review and solidify CRAWL skills from Chapters 1-8 (Final Exam preparation)\n",
    "- ðŸš¶ Connect concepts across chapters to solve multi-step problems\n",
    "- ðŸš€ Complete an end-to-end data analysis project with AI collaboration\n",
    "- ðŸš€ Document your analysis process for reproducibility\n",
    "- ðŸš€ Create a professional deliverable combining code, visualizations, and narrative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ› CRAWL: Final Exam Review\n",
    "\n",
    "**Rules for this section:**\n",
    "- Close all AI tools (ChatGPT, Claude, Copilot, etc.)\n",
    "- Work through these problems using only your knowledge\n",
    "- This directly prepares you for the final exam\n",
    "\n",
    "**If you struggle with any section, go back and review that chapter before the exam.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Comprehensive Review: Can You Do This Without AI?\n",
    "\n",
    "The following exercises test the core skills from each chapter. Time yourself: you should complete each section in 5-10 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 1 Review: Variables, Types, Expressions\n",
    "\n",
    "Without running the code, predict the output of each expression. Then verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the output BEFORE running\n",
    "\n",
    "# 1. What is the result and type?\n",
    "a = 105 / 15\n",
    "print(f\"a = {a}, type = {type(a).__name__}\")\n",
    "\n",
    "# 2. What is the result and type?\n",
    "b = 105 // 15\n",
    "print(f\"b = {b}, type = {type(b).__name__}\")\n",
    "\n",
    "# 3. What is the result?\n",
    "c = 105 % 15\n",
    "print(f\"c = {c}\")\n",
    "\n",
    "# 4. What does this print?\n",
    "gpa = 3.456\n",
    "print(f\"GPA: {gpa:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your predictions:**\n",
    "1. a = _____, type = _____\n",
    "2. b = _____, type = _____\n",
    "3. c = _____\n",
    "4. Output: _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 2 Review: Control Flow\n",
    "\n",
    "Write code to classify a student's academic standing based on GPA:\n",
    "- 3.5 and above: \"Dean's List\"\n",
    "- 2.0 to 3.5 (not including 3.5): \"Good Standing\"\n",
    "- Below 2.0: \"Academic Probation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your classification code here\n",
    "gpa = 3.45\n",
    "\n",
    "# Your code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 3 Review: Functions\n",
    "\n",
    "Write a function `completion_rate(attempted, earned)` that:\n",
    "- Returns the completion rate as a percentage (0-100)\n",
    "- Returns 0.0 if attempted is 0 (avoid division by zero)\n",
    "- Includes a docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your function here\n",
    "\n",
    "\n",
    "# Test it\n",
    "print(completion_rate(100, 95))  # Should print 95.0\n",
    "print(completion_rate(0, 0))      # Should print 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 4 Review: Data Structures\n",
    "\n",
    "Given the following student data, answer the questions using only basic Python (no pandas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "students = [\n    {\"id\": \"CU001\", \"college\": \"Business\", \"gpa\": 3.5},\n    {\"id\": \"CU002\", \"college\": \"Engineering\", \"gpa\": 3.2},\n    {\"id\": \"CU003\", \"college\": \"Business\", \"gpa\": 3.8},\n    {\"id\": \"CU004\", \"college\": \"Arts\", \"gpa\": 2.9},\n    {\"id\": \"CU005\", \"college\": \"Engineering\", \"gpa\": 3.6},\n]\n\n# 1. Get all unique colleges (use a set)\n\n\n# 2. Calculate the average GPA across all students\n\n\n# 3. Find the student with the highest GPA\n\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 5 Review: File I/O and Exceptions\n",
    "\n",
    "Write code that:\n",
    "1. Tries to open a file called 'nonexistent.csv'\n",
    "2. If the file doesn't exist, prints \"File not found\" instead of crashing\n",
    "3. Uses a `with` statement for proper file handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your exception handling code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 6 Review: NumPy\n",
    "\n",
    "Without running, predict what each operation produces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "gpas = np.array([3.5, 3.2, 3.8, 2.9, 3.6])\n",
    "\n",
    "# Predict BEFORE running:\n",
    "print(gpas[gpas > 3.5])           # What values?\n",
    "print(np.mean(gpas))              # What number?\n",
    "print(gpas * 2)                   # What array?\n",
    "print(len(gpas[gpas >= 3.0]))     # What count?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your predictions:**\n",
    "1. gpas[gpas > 3.5] = _____\n",
    "2. np.mean(gpas) = _____\n",
    "3. gpas * 2 = _____\n",
    "4. len(gpas[gpas >= 3.0]) = _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 7 Review: Pandas\n",
    "\n",
    "Answer without running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume df has columns: Student_ID, College, GPA, Credits_Attempted, Credits_Earned\n",
    "\n",
    "# Which code correctly calculates average GPA by college?\n",
    "# A: df.groupby('College').mean('GPA')\n",
    "# B: df.groupby('College')['GPA'].mean()\n",
    "# C: df['GPA'].groupby('College').mean()\n",
    "# D: df.mean().groupby('College')['GPA']\n",
    "\n",
    "# Your answer: ___\n",
    "\n",
    "# Which code correctly filters for students with GPA > 3.5 AND in Business?\n",
    "# A: df[df['GPA'] > 3.5 and df['College'] == 'Business']\n",
    "# B: df[df['GPA'] > 3.5 & df['College'] == 'Business']\n",
    "# C: df[(df['GPA'] > 3.5) & (df['College'] == 'Business')]\n",
    "# D: df.filter(GPA > 3.5, College == 'Business')\n",
    "\n",
    "# Your answer: ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 8 Review: Visualization\n",
    "\n",
    "Match the chart type to the question it best answers:\n",
    "\n",
    "| Question | Chart Type |\n",
    "|----------|------------|\n",
    "| 1. What is the distribution of GPA values? | A. Bar chart |\n",
    "| 2. How many students are in each college? | B. Scatter plot |\n",
    "| 3. Is there a relationship between credits and GPA? | C. Histogram |\n",
    "| 4. How do GPA distributions differ by college? | D. Box plot |\n",
    "\n",
    "**Your answers:** 1=___, 2=___, 3=___, 4=___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9.2 Connecting the Pieces: Multi-Step Problems\n",
    "\n",
    "The final exam will include problems that span multiple chapters. Practice these:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Problem: Complete the Pipeline\n\nWrite code that:\n1. Loads `data/crestview_students_extended.csv` into a pandas DataFrame\n2. Adds a new column `completion_rate` = Credits_Earned / Credits_Attempted * 100\n3. Filters for students on Academic Probation (GPA < 2.0)\n4. Calculates the average completion rate for these at-risk students\n5. Prints the result formatted to 1 decimal place"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this pipeline (no AI)\n",
    "import pandas as pd\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸš¶ WALK: Building Analysis Workflows\n",
    "\n",
    "**Rules for this section:**\n",
    "- You may use AI to explain concepts and help understand errors\n",
    "- You must write all code yourself\n",
    "- Focus on understanding WHY each step is necessary\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 The Anatomy of a Data Analysis\n",
    "\n",
    "Let's walk through a complete analysis together, with commentary explaining each decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Step 1: Define the Question\n\n**Scenario:** The Provost's office wants to understand which factors are associated with academic success at Crestview. They've asked you to analyze student data and provide actionable recommendations.\n\n**Primary Questions:**\n1. Are there performance differences across colleges?\n2. Do students improve over time (First Year â†’ Senior)?\n3. What characterizes students who struggle academically?\n4. What early warning signs might identify at-risk students?\n\n**Why This Matters:** A clear question drives every subsequent decision. Without it, you'll produce analysis that looks impressive but doesn't help anyone make decisions."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Acquire and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set display options\npd.set_option('display.max_columns', 15)\npd.set_option('display.width', 120)\n\n# Set plot style\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette('husl')\n\n# Load the extended Crestview student dataset (15 variables)\ndf = pd.read_csv('data/crestview_students_extended.csv')\n\nprint(f\"Loaded {len(df):,} student records with {len(df.columns)} variables\")\nprint(f\"\\nColumns: {df.columns.tolist()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Validate and Understand the Data\n",
    "\n",
    "Before any analysis, verify that the data is what you expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Basic inspection\nprint(\"=\" * 60)\nprint(\"DATA QUALITY CHECK\")\nprint(\"=\" * 60)\n\n# Check for missing values\nprint(\"\\nMissing Values:\")\nprint(df.isnull().sum())\n# Note: First_Generation has ~10% blank values (students who preferred not to answer)\n\n# Check data types\nprint(\"\\nData Types:\")\nprint(df.dtypes)\n\n# Check for unexpected values\nprint(\"\\nGPA Range:\", df['GPA'].min(), \"to\", df['GPA'].max())\nprint(\"Credits Range:\", df['Credits_Attempted'].min(), \"to\", df['Credits_Attempted'].max())\nprint(\"Study Hours Range:\", df['Study_Hours_Per_Week'].min(), \"to\", df['Study_Hours_Per_Week'].max())\nprint(\"Distance From Home Range:\", df['Distance_From_Home'].min(), \"to\", df['Distance_From_Home'].max())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check categorical variables\nprint(\"\\nColleges:\")\nprint(df['College'].value_counts())\n\nprint(\"\\nClass Years:\")\nprint(df['Class_Year'].value_counts())\n\nprint(\"\\nCampus Housing:\")\nprint(df['Campus_Housing'].value_counts())\n\nprint(\"\\nFinancial Aid:\")\nprint(df['Financial_Aid'].value_counts())\n\nprint(\"\\nFirst Generation (note blanks):\")\nprint(df['First_Generation'].value_counts(dropna=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Derived Variables\n",
    "\n",
    "Add calculated fields that will help answer our questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create useful derived columns\ndf['Completion_Rate'] = (df['Credits_Earned'] / df['Credits_Attempted'] * 100).round(1)\n\n# Create academic standing categories\ndef classify_standing(gpa):\n    if gpa >= 3.5:\n        return \"Dean's List\"\n    elif gpa >= 2.0:\n        return \"Good Standing\"\n    else:\n        return \"Probation\"\n\ndf['Academic_Standing'] = df['GPA'].apply(classify_standing)\n\n# New derived columns from the extended dataset\ndf['Study_Efficiency'] = (df['GPA'] / df['Study_Hours_Per_Week']).round(3)\ndf['Has_Job'] = df['Part_Time_Job'] != 'No'\n\n# Check our new columns\nprint(df[['Student_ID', 'GPA', 'Academic_Standing', 'Completion_Rate', \n           'Study_Hours_Per_Week', 'Study_Efficiency', 'Has_Job']].head(10))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Exploratory Analysis\n",
    "\n",
    "Now we systematically answer each of our questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Question 1: Performance differences across colleges\nprint(\"=\" * 60)\nprint(\"QUESTION 1: Performance by College\")\nprint(\"=\" * 60)\n\ncollege_stats = df.groupby('College').agg({\n    'GPA': ['mean', 'std', 'count'],\n    'Completion_Rate': 'mean',\n    'Study_Hours_Per_Week': 'mean',\n    'Distance_From_Home': 'mean'\n}).round(3)\n\ncollege_stats.columns = ['Avg_GPA', 'Std_GPA', 'Count', 'Avg_Completion', 'Avg_Study_Hours', 'Avg_Distance']\nprint(college_stats.sort_values('Avg_GPA', ascending=False))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Question 2: Progression over class years\nprint(\"\\n\" + \"=\" * 60)\nprint(\"QUESTION 2: Performance by Class Year\")\nprint(\"=\" * 60)\n\n# Define logical order for class years\nyear_order = ['First Year', 'Sophomore', 'Junior', 'Senior', 'Graduate']\n\nyear_stats = df.groupby('Class_Year').agg({\n    'GPA': ['mean', 'std'],\n    'Completion_Rate': 'mean',\n    'Study_Hours_Per_Week': 'mean',\n    'Student_ID': 'count'\n}).round(3)\n\nyear_stats.columns = ['Avg_GPA', 'Std_GPA', 'Avg_Completion', 'Avg_Study_Hours', 'Count']\nyear_stats = year_stats.reindex(year_order)\nprint(year_stats)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Question 3: Characteristics of struggling students\nprint(\"\\n\" + \"=\" * 60)\nprint(\"QUESTION 3: At-Risk Student Profile\")\nprint(\"=\" * 60)\n\nat_risk = df[df['GPA'] < 2.0]\nprint(f\"\\nStudents on Academic Probation: {len(at_risk)} ({len(at_risk)/len(df)*100:.1f}%)\")\n\nprint(\"\\nBreakdown by College:\")\nprint(at_risk['College'].value_counts())\n\nprint(\"\\nBreakdown by Class Year:\")\nprint(at_risk['Class_Year'].value_counts())\n\nprint(f\"\\nAverage Completion Rate (At-Risk): {at_risk['Completion_Rate'].mean():.1f}%\")\nprint(f\"Average Completion Rate (All): {df['Completion_Rate'].mean():.1f}%\")\n\nprint(f\"\\nAverage Study Hours (At-Risk): {at_risk['Study_Hours_Per_Week'].mean():.1f}\")\nprint(f\"Average Study Hours (All): {df['Study_Hours_Per_Week'].mean():.1f}\")\n\nprint(f\"\\nHousing Distribution (At-Risk):\")\nprint(at_risk['Campus_Housing'].value_counts())\n\nprint(f\"\\nFinancial Aid (At-Risk):\")\nprint(at_risk['Financial_Aid'].value_counts())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Visualization\n",
    "\n",
    "Create visualizations that communicate findings clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create a comprehensive figure\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Plot 1: GPA Distribution by College\nsns.boxplot(data=df, x='College', y='GPA', ax=axes[0, 0])\naxes[0, 0].set_title('GPA Distribution by College', fontsize=12, fontweight='bold')\naxes[0, 0].tick_params(axis='x', rotation=45)\naxes[0, 0].axhline(y=2.0, color='red', linestyle='--', alpha=0.7, label='Probation Line')\naxes[0, 0].axhline(y=3.5, color='green', linestyle='--', alpha=0.7, label=\"Dean's List\")\n\n# Plot 2: GPA by Class Year\nyear_order = ['First Year', 'Sophomore', 'Junior', 'Senior', 'Graduate']\nsns.boxplot(data=df, x='Class_Year', y='GPA', order=year_order, ax=axes[0, 1])\naxes[0, 1].set_title('GPA Progression by Class Year', fontsize=12, fontweight='bold')\naxes[0, 1].axhline(y=2.0, color='red', linestyle='--', alpha=0.7)\n\n# Plot 3: Study Hours vs GPA (colored by Campus Housing)\nfor housing in df['Campus_Housing'].unique():\n    subset = df[df['Campus_Housing'] == housing]\n    axes[1, 0].scatter(subset['Study_Hours_Per_Week'], subset['GPA'], \n                        alpha=0.4, s=30, label=housing)\naxes[1, 0].set_xlabel('Study Hours Per Week')\naxes[1, 0].set_ylabel('GPA')\naxes[1, 0].set_title('Study Hours vs GPA by Housing', fontsize=12, fontweight='bold')\naxes[1, 0].legend(fontsize=8)\n\n# Plot 4: Academic Standing Distribution\nstanding_counts = df['Academic_Standing'].value_counts()\ncolors = ['#2ecc71', '#3498db', '#e74c3c']  # Green, Blue, Red\naxes[1, 1].pie(standing_counts, labels=standing_counts.index, autopct='%1.1f%%', \n               colors=colors, startangle=90)\naxes[1, 1].set_title('Academic Standing Distribution', fontsize=12, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('student_analysis_overview.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Synthesize Findings\n",
    "\n",
    "Convert analysis into actionable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"EXECUTIVE SUMMARY: Crestview University Student Performance Analysis\")\nprint(\"=\" * 70)\n\nprint(\"\\nðŸ“Š KEY FINDINGS:\")\nprint(\"â”€\" * 50)\n\n# Finding 1: Overall health\nprobation_pct = (df['GPA'] < 2.0).mean() * 100\ndeans_list_pct = (df['GPA'] >= 3.5).mean() * 100\nprint(f\"\\n1. OVERALL ACADEMIC HEALTH\")\nprint(f\"   â€¢ {deans_list_pct:.1f}% of students qualify for Dean's List (GPA â‰¥ 3.5)\")\nprint(f\"   â€¢ {probation_pct:.1f}% of students are on Academic Probation (GPA < 2.0)\")\n\n# Finding 2: College differences\nbest_college = college_stats['Avg_GPA'].idxmax()\nworst_college = college_stats['Avg_GPA'].idxmin()\ngpa_gap = college_stats.loc[best_college, 'Avg_GPA'] - college_stats.loc[worst_college, 'Avg_GPA']\nprint(f\"\\n2. COLLEGE PERFORMANCE GAP\")\nprint(f\"   â€¢ Highest avg GPA: {best_college} ({college_stats.loc[best_college, 'Avg_GPA']:.2f})\")\nprint(f\"   â€¢ Lowest avg GPA: {worst_college} ({college_stats.loc[worst_college, 'Avg_GPA']:.2f})\")\nprint(f\"   â€¢ Performance gap: {gpa_gap:.2f} GPA points\")\n\n# Finding 3: Study hours and success\nstudy_corr = df['Study_Hours_Per_Week'].corr(df['GPA'])\nprint(f\"\\n3. STUDY HABITS AND SUCCESS\")\nprint(f\"   â€¢ Study hours-GPA correlation: {study_corr:.3f}\")\navg_study_deans = df[df['GPA'] >= 3.5]['Study_Hours_Per_Week'].mean()\navg_study_probation = df[df['GPA'] < 2.0]['Study_Hours_Per_Week'].mean()\nprint(f\"   â€¢ Dean's List avg study hours: {avg_study_deans:.1f} hrs/week\")\nprint(f\"   â€¢ Probation avg study hours: {avg_study_probation:.1f} hrs/week\")\n\n# Finding 4: Class year progression\nfirst_year_gpa = year_stats.loc['First Year', 'Avg_GPA']\nsenior_gpa = year_stats.loc['Senior', 'Avg_GPA']\nprint(f\"\\n4. CLASS YEAR PROGRESSION\")\nprint(f\"   â€¢ First Year avg GPA: {first_year_gpa:.2f}\")\nprint(f\"   â€¢ Senior avg GPA: {senior_gpa:.2f}\")\nprint(f\"   â€¢ Improvement: +{senior_gpa - first_year_gpa:.2f} GPA points\")\n\n# Finding 5: Housing and outcomes\nhousing_gpas = df.groupby('Campus_Housing')['GPA'].mean()\nprint(f\"\\n5. HOUSING AND OUTCOMES\")\nfor housing, gpa in housing_gpas.sort_values(ascending=False).items():\n    print(f\"   â€¢ {housing}: {gpa:.2f} avg GPA\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"ðŸ’¡ RECOMMENDATIONS:\")\nprint(\"â”€\" * 50)\nprint(\"\\n1. Implement early warning system using study hours + first-semester completion rates\")\nprint(\"2. Investigate support resources in colleges with lower average GPAs\")\nprint(\"3. Strengthen first-year orientation and study skills programs\")\nprint(\"4. Explore whether housing type affects academic outcomes (and if so, why)\")\nprint(\"5. Consider targeted outreach for students with part-time jobs and low study hours\")\nprint(\"\\n\" + \"=\" * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸš€ RUN: Capstone Analysis Project\n",
    "\n",
    "**Rules for this section:**\n",
    "- Full AI collaboration is encouraged\n",
    "- Document how you use AI and what you learn\n",
    "- Focus on creating a professional-quality deliverable\n",
    "- You must be able to explain every line of code\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9.4 Capstone Project: Your Analysis Challenge\n\nYou're working with the **extended dataset** (600 students, 15 variables) â€” the same rich dataset you've used in Chapters 6-8. You now have Study_Hours_Per_Week, Campus_Housing, Financial_Aid, Extracurriculars, Part_Time_Job, First_Generation, and Distance_From_Home at your disposal alongside the core GPA, credits, college, and class year data.\n\nChoose ONE of the following analysis challenges. Complete a full analysis including:\n\n1. **Clear problem statement** (1-2 sentences)\n2. **Data preparation** (loading, cleaning, derived variables)\n3. **Exploratory analysis** (summary statistics, groupings)\n4. **Visualizations** (at least 4 publication-quality figures)\n5. **Key findings** (3-5 bullet points)\n6. **Recommendations** (actionable next steps)\n7. **AI collaboration log** (how did you use AI?)\n\n---\n\n### Option A: Major Comparison Study\n\n**Question:** Which majors have the strongest academic outcomes, and what might explain the differences?\n\n**Required Analysis:**\n- Compare GPAs across all majors (minimum 10 students per major)\n- Identify outlier majors (unusually high or low performance)\n- Examine completion rates by major\n- Control for college effects (do major differences persist within colleges?)\n- Do study habits differ by major? (Compare study hours and extracurriculars)\n- Are certain majors associated with more part-time work?\n\n---\n\n### Option B: Early Warning System Design\n\n**Question:** Can we identify students likely to struggle academically based on early indicators?\n\n**Required Analysis:**\n- Profile students who end up on academic probation\n- Identify patterns in completion rates that predict low GPA\n- Compare first-year students who succeed vs. struggle\n- Analyze whether study hours, housing type, and first-generation status are early indicators\n- Propose specific thresholds for an early warning system (e.g., study hours < X, GPA < Y after first semester)\n\n---\n\n### Option C: Resource Allocation Analysis\n\n**Question:** If the university can only invest in supporting one group of students, where should resources go?\n\n**Required Analysis:**\n- Compare academic outcomes across all colleges\n- Identify which college has the most students at risk\n- Analyze the role of financial aid â€” do students with partial aid struggle more?\n- Examine housing and distance from home as factors in student success\n- Calculate potential impact of improvement\n- Make and defend your recommendation using data from all 15 variables\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Capstone Project\n",
    "\n",
    "**Selected Option:** [A / B / C]\n",
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "*Write your problem statement here (1-2 sentences)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your data loading and preparation code\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "\n",
    "\n",
    "# Create derived variables\n",
    "\n",
    "\n",
    "# Data quality checks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your exploratory analysis code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings\n",
    "\n",
    "*Summarize your 3-5 key findings here:*\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "4. \n",
    "5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "*Based on your analysis, what actions should the university take?*\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Collaboration Log\n",
    "\n",
    "Document how you used AI during this project:\n",
    "\n",
    "| Task | AI Used? | What I Asked | What I Learned |\n",
    "|------|----------|--------------|----------------|\n",
    "| Data loading | | | |\n",
    "| Creating visualizations | | | |\n",
    "| Debugging errors | | | |\n",
    "| Interpreting results | | | |\n",
    "| Writing recommendations | | | |\n",
    "\n",
    "**Reflection:** What did AI help you do faster? What did you still need to figure out yourself?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Accountability Check\n",
    "\n",
    "## ðŸ› CRAWL (Must do without AI - FINAL EXAM MATERIAL)\n",
    "\n",
    "### From Chapter 1:\n",
    "- [ ] Create variables with appropriate names and types\n",
    "- [ ] Perform arithmetic operations including `/`, `//`, `%`\n",
    "- [ ] Use f-strings with format specifiers (`.2f`, `.1%`)\n",
    "\n",
    "### From Chapter 2:\n",
    "- [ ] Write if/elif/else statements\n",
    "- [ ] Use comparison operators (`<`, `>`, `==`, `!=`, `<=`, `>=`)\n",
    "- [ ] Combine conditions with `and`, `or`, `not`\n",
    "- [ ] Write for loops and while loops\n",
    "\n",
    "### From Chapter 3:\n",
    "- [ ] Define functions with parameters and return values\n",
    "- [ ] Write docstrings\n",
    "- [ ] Understand scope (local vs global variables)\n",
    "\n",
    "### From Chapter 4:\n",
    "- [ ] Create and manipulate lists, dictionaries, and sets\n",
    "- [ ] Use list/dict comprehensions\n",
    "- [ ] Iterate through data structures\n",
    "\n",
    "### From Chapter 5:\n",
    "- [ ] Open, read, and write files using `with` statements\n",
    "- [ ] Handle exceptions with try/except\n",
    "- [ ] Parse CSV files\n",
    "\n",
    "### From Chapter 6:\n",
    "- [ ] Create NumPy arrays and perform vectorized operations\n",
    "- [ ] Use boolean indexing to filter arrays\n",
    "- [ ] Calculate basic statistics (mean, std, min, max)\n",
    "\n",
    "### From Chapter 7:\n",
    "- [ ] Load CSV files with `pd.read_csv()`\n",
    "- [ ] Inspect DataFrames with `head()`, `info()`, `describe()`\n",
    "- [ ] Select columns and filter rows\n",
    "- [ ] Use `groupby()` for aggregations\n",
    "- [ ] Create new columns from existing data\n",
    "\n",
    "### From Chapter 8:\n",
    "- [ ] Create basic plots with matplotlib (histogram, bar, scatter)\n",
    "- [ ] Add titles, labels, and legends\n",
    "- [ ] Create multi-panel figures with subplots\n",
    "- [ ] Save figures to files\n",
    "\n",
    "## ðŸš¶ WALK (AI to learn, write code yourself)\n",
    "- [ ] Chain multiple pandas operations together\n",
    "- [ ] Create pivot tables\n",
    "- [ ] Use seaborn for statistical visualizations\n",
    "- [ ] Handle missing values appropriately\n",
    "\n",
    "## ðŸš€ RUN (AI-assisted, must understand completely)\n",
    "- [ ] Complete an end-to-end data analysis\n",
    "- [ ] Create professional-quality visualizations\n",
    "- [ ] Translate analysis into actionable recommendations\n",
    "- [ ] Document your process and AI collaboration\n",
    "\n",
    "**If you cannot check all CRAWL boxes from memory, review those chapters before the final exam.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Exam Preparation\n",
    "\n",
    "The final exam will:\n",
    "\n",
    "1. **Test CRAWL skills without AI** - You must be able to write basic Python code, use pandas for data manipulation, and create simple visualizations from memory.\n",
    "\n",
    "2. **Include code reading questions** - Given code, predict the output or identify errors.\n",
    "\n",
    "3. **Require connecting concepts** - Problems will span multiple chapters (e.g., load data, filter it, calculate statistics, describe what visualization would be appropriate).\n",
    "\n",
    "4. **Not require memorizing syntax details** - You won't need to remember exact parameter names, but you need to know what's possible and write approximately correct code.\n",
    "\n",
    "**Best preparation:**\n",
    "- Review the Accountability Checklists from all chapters\n",
    "- Redo the CRAWL exercises without looking at solutions\n",
    "- Practice explaining code out loud\n",
    "- If you can't do something without AI, you don't know it well enough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Course Completion\n\nCongratulations on completing BUAN 446: Python for Data Analysts!\n\n**What You've Learned:**\n\n| Chapters | Topics | Skills |\n|----------|--------|--------|\n| 1-4 | Python Fundamentals | Variables, control flow, functions, data structures |\n| 5 | Files, Exceptions & Cleaning | Real-world data, error handling, messy data (midterm) |\n| 6 | NumPy | Numerical computing, vectorization, correlation analysis |\n| 7 | Pandas | Data manipulation, groupby, merge, pivot tables |\n| 8 | Visualization | Matplotlib, Seaborn, dashboards, communication |\n| 9 | Complete Workflow | End-to-end analysis, professional deliverables |\n\n**The Three-Dataset Journey:**\n\n| Phase | Dataset | Variables | Purpose |\n|-------|---------|-----------|---------|\n| Chapters 1-4 | Clean (7 vars) | Core student data | Learn Python without distractions |\n| Chapter 5 | Messy (8 vars) | 20+ quality issues | Learn what real data looks like |\n| Chapters 6-9 | Extended (15 vars) | Study hours, housing, aid, etc. | Perform rich, multi-dimensional analysis |\n\n**The CRAWL-WALK-RUN Framework:**\n\nYou've learned not just Python, but how to learn with AI effectively:\n\n- **CRAWL** taught you that foundational skills require practice without shortcuts\n- **WALK** showed you how to use AI as a learning accelerator, not a crutch\n- **RUN** demonstrated that AI collaboration amplifies (but doesn't replace) competence\n\n**What's Next:**\n\nThe skills you've built transfer directly to professional data analysis work. Whether you're going into finance, marketing, consulting, or tech, the ability to:\n\n- Load and clean messy data\n- Explore patterns and relationships across multiple variables\n- Communicate findings visually\n- Collaborate effectively with AI tools\n\n...will set you apart.\n\nGood luck on the final exam, and congratulations on your hard work this semester!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}