{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: File I/O and Exception Handling\n",
    "\n",
    "---\n",
    "\n",
    "## The CRAWL â†’ WALK â†’ RUN Framework\n",
    "\n",
    "This textbook uses a structured approach to learning Python while developing effective AI collaboration skills. Each chapter follows three distinct phases:\n",
    "\n",
    "| Mode | Icon | AI Policy | Purpose |\n",
    "|------|------|-----------|--------|\n",
    "| **CRAWL** | ðŸ› | No AI assistance | Build foundational skills you can demonstrate independently |\n",
    "| **WALK** | ðŸš¶ | AI for understanding only | Use AI to explain concepts and errors, but write your own code |\n",
    "| **RUN** | ðŸš€ | Full AI collaboration | Partner with AI on complex tasks while documenting your process |\n",
    "\n",
    "**Why This Matters:** Your exams will test CRAWL and WALK material with no AI assistance. If you skip the foundational work and rely entirely on AI, you won't pass. The progression ensures you build genuine competence before leveraging AI as a professional tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Case Study: From Clean to Messy Data\n",
    "\n",
    "This is the chapter where theory meets reality. You've been working with data structures in memory. Now you'll learn to:\n",
    "\n",
    "- **Read data from files** on disk into Python\n",
    "- **Write results back** to files for sharing\n",
    "- **Handle errors gracefully** when files don't exist or data is corrupted\n",
    "- **Process the messy Lehigh dataset** with all its real-world problems\n",
    "\n",
    "**The Big Picture:**\n",
    "\n",
    "| File | Records | Columns | Quality | Use |\n",
    "|------|---------|---------|---------|-----|\n",
    "| `lehigh_students_clean.csv` | 600 | 7 | Perfect | Learning file I/O basics |\n",
    "| `lehigh_students_messy.csv` | 605 | 8 | Intentionally degraded | Data cleaning project |\n",
    "\n",
    "The messy dataset has 28+ data quality issues including:\n",
    "- Inconsistent college names (\"COB\", \"Business\", \"college of business\")\n",
    "- Missing GPA values\n",
    "- Duplicate student records\n",
    "- Invalid values (GPA > 4.0)\n",
    "- Multiple date formats\n",
    "\n",
    "By the end of this chapter, you'll have the tools to detect and handle all of these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this chapter, you will:\n",
    "\n",
    "- ðŸ› Open, read, and close files using `open()` and file modes\n",
    "- ðŸ› Read entire files, read line by line, and write to files\n",
    "- ðŸ› Use `with` statements for safe file handling\n",
    "- ðŸ› Parse CSV files using the `csv` module\n",
    "- ðŸ› Handle common exceptions with `try/except` blocks\n",
    "- ðŸš¶ Work with different file encodings (UTF-8, Latin-1)\n",
    "- ðŸš¶ Raise your own exceptions for data validation\n",
    "- ðŸš¶ Use `finally` for cleanup operations\n",
    "- ðŸš€ Build a complete data cleaning pipeline for the messy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ› CRAWL: Reading and Writing Files\n",
    "\n",
    "**Rules for this section:**\n",
    "- Close all AI tools (ChatGPT, Claude, Copilot, etc.)\n",
    "- Work through examples by typing them yourself\n",
    "- Use only this notebook, Python documentation, or your instructor for help\n",
    "- This material will appear on exams without AI assistance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š DataCamp Resources for Chapter 5\n",
    "\n",
    "**[Introduction to Importing Data in Python](https://www.datacamp.com/courses/introduction-to-importing-data-in-python)** - Complete these:\n",
    "\n",
    "| Chapter | Topics Covered | Alignment |\n",
    "|---------|---------------|------------|\n",
    "| Chapter 1: Introduction and flat files | Reading text files, CSV files | Sections 5.1-5.4 |\n",
    "\n",
    "**[Writing Functions in Python](https://www.datacamp.com/courses/writing-functions-in-python)** - Complete these:\n",
    "\n",
    "| Chapter | Topics Covered | Alignment |\n",
    "|---------|---------------|------------|\n",
    "| Chapter 4: More on Decorators (Error Handling section) | Exception handling | Sections 5.5-5.7 |\n",
    "\n",
    "**Estimated time:** 2-3 hours total\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Opening Files with `open()`\n",
    "\n",
    "The `open()` function creates a connection between your Python code and a file on disk. You must specify:\n",
    "\n",
    "1. **File path** - where the file is located\n",
    "2. **Mode** - what you want to do with the file\n",
    "\n",
    "| Mode | Meaning | Creates file? | Erases existing? |\n",
    "|------|---------|---------------|------------------|\n",
    "| `'r'` | Read (default) | No | No |\n",
    "| `'w'` | Write | Yes | **Yes!** |\n",
    "| `'a'` | Append | Yes | No |\n",
    "| `'r+'` | Read and write | No | No |\n",
    "\n",
    "**Warning:** Mode `'w'` will destroy any existing file content without warning. Be careful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create a simple text file to work with\n",
    "# We'll use write mode to create it\n",
    "\n",
    "file = open('sample_students.txt', 'w')\n",
    "file.write('Student_ID,GPA,Major\\n')\n",
    "file.write('LU100001,3.41,Finance\\n')\n",
    "file.write('LU100002,3.55,Computer Science\\n')\n",
    "file.write('LU100003,2.85,Biology\\n')\n",
    "file.close()  # Always close files when done!\n",
    "\n",
    "print(\"File created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read the file we just created\n",
    "file = open('sample_students.txt', 'r')\n",
    "content = file.read()  # Read entire file as one string\n",
    "file.close()\n",
    "\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read line by line\n",
    "file = open('sample_students.txt', 'r')\n",
    "\n",
    "line1 = file.readline()  # Reads first line\n",
    "line2 = file.readline()  # Reads second line\n",
    "\n",
    "print(f\"Line 1: {line1}\")\n",
    "print(f\"Line 2: {line2}\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the extra blank lines? That's because each line in the file ends with `\\n` (newline), and `print()` adds another newline. You'll often want to strip these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all lines into a list\n",
    "file = open('sample_students.txt', 'r')\n",
    "lines = file.readlines()  # Returns a list of strings\n",
    "file.close()\n",
    "\n",
    "print(f\"Number of lines: {len(lines)}\")\n",
    "print(f\"Lines: {lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the newlines\n",
    "file = open('sample_students.txt', 'r')\n",
    "lines = file.readlines()\n",
    "file.close()\n",
    "\n",
    "for line in lines:\n",
    "    clean_line = line.strip()  # Remove leading/trailing whitespace including \\n\n",
    "    print(clean_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 The `with` Statement (Context Manager)\n",
    "\n",
    "Forgetting to close files is a common bug that can cause data loss or resource leaks. The `with` statement automatically closes the file when you're done, even if an error occurs.\n",
    "\n",
    "**Always use `with` for file operations.** It's cleaner and safer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The proper way to read files\n",
    "with open('sample_students.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)\n",
    "\n",
    "# File is automatically closed here, even if an error occurred\n",
    "print(\"File is now closed:\", file.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process line by line (memory efficient for large files)\n",
    "with open('sample_students.txt', 'r') as file:\n",
    "    for line in file:  # Iterate directly over the file object\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing with 'with'\n",
    "students = [\n",
    "    (\"LU100004\", 3.92, \"Psychology\"),\n",
    "    (\"LU100005\", 2.10, \"Marketing\"),\n",
    "    (\"LU100006\", 3.78, \"Economics\")\n",
    "]\n",
    "\n",
    "with open('new_students.txt', 'w') as file:\n",
    "    file.write(\"Student_ID,GPA,Major\\n\")  # Header\n",
    "    for student_id, gpa, major in students:\n",
    "        file.write(f\"{student_id},{gpa},{major}\\n\")\n",
    "\n",
    "print(\"File written!\")\n",
    "\n",
    "# Verify it worked\n",
    "with open('new_students.txt', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append mode adds to the end without erasing\n",
    "with open('new_students.txt', 'a') as file:\n",
    "    file.write(\"LU100007,3.45,History\\n\")\n",
    "\n",
    "# Check the result\n",
    "with open('new_students.txt', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Working with File Paths\n",
    "\n",
    "File paths can be:\n",
    "- **Relative:** Relative to your current working directory (`'data/students.csv'`)\n",
    "- **Absolute:** Full path from root (`'/home/user/data/students.csv'` or `'C:\\\\Users\\\\data\\\\students.csv'`)\n",
    "\n",
    "Use forward slashes `/` even on Windows, or use raw strings `r'C:\\path\\to\\file'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# What's the current working directory?\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# List files in current directory\n",
    "print(f\"Files here: {os.listdir('.')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a file exists before trying to open it\n",
    "filename = 'sample_students.txt'\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    print(f\"{filename} exists!\")\n",
    "    with open(filename, 'r') as file:\n",
    "        print(file.read())\n",
    "else:\n",
    "    print(f\"{filename} not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build paths safely using os.path.join\n",
    "# This handles path separators correctly on any operating system\n",
    "\n",
    "folder = 'data'\n",
    "filename = 'students.csv'\n",
    "\n",
    "full_path = os.path.join(folder, filename)\n",
    "print(f\"Full path: {full_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Reading CSV Files with the `csv` Module\n",
    "\n",
    "CSV (Comma-Separated Values) is the most common format for tabular data. While you could split lines by commas yourself, the `csv` module handles edge cases like:\n",
    "- Values containing commas (enclosed in quotes)\n",
    "- Values containing newlines\n",
    "- Different delimiters (tabs, semicolons)\n",
    "\n",
    "This is what you'll use to load the Lehigh student datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Create a CSV file with some edge cases\n",
    "with open('tricky_data.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Name', 'College', 'Notes'])\n",
    "    writer.writerow(['Alice Smith', 'College of Business', 'Dean\\'s List'])\n",
    "    writer.writerow(['Bob Jones', 'Engineering', 'Transferred from \"State U\"'])  # Quotes in value\n",
    "    writer.writerow(['Charlie Brown', 'Arts, Sciences', 'Double major'])  # Comma in value\n",
    "\n",
    "print(\"CSV written!\")\n",
    "\n",
    "# Look at the raw file\n",
    "with open('tricky_data.csv', 'r') as file:\n",
    "    print(\"Raw file contents:\")\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read with csv.reader\n",
    "with open('tricky_data.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        print(row)  # Each row is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv.DictReader gives you dictionaries instead of lists\n",
    "# This is usually more convenient\n",
    "\n",
    "with open('tricky_data.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        print(f\"  Name: {row['Name']}\")\n",
    "        print(f\"  College: {row['College']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing with csv.DictWriter\n",
    "students = [\n",
    "    {'id': 'LU100001', 'gpa': 3.41, 'college': 'Business'},\n",
    "    {'id': 'LU100002', 'gpa': 3.55, 'college': 'Engineering'},\n",
    "    {'id': 'LU100003', 'gpa': 2.85, 'college': 'Health'},\n",
    "]\n",
    "\n",
    "with open('output_students.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['id', 'gpa', 'college']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()  # Write the header row\n",
    "    writer.writerows(students)  # Write all data rows\n",
    "\n",
    "# Verify\n",
    "with open('output_students.csv', 'r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Lehigh Student Dataset\n",
    "\n",
    "Now let's load the actual clean dataset. The file should be in your course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clean Lehigh dataset\n",
    "# Adjust the path based on where your file is located\n",
    "\n",
    "students = []\n",
    "\n",
    "with open('lehigh_students_clean.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        students.append(row)\n",
    "\n",
    "print(f\"Loaded {len(students)} students\")\n",
    "print(f\"\\nFirst student: {students[0]}\")\n",
    "print(f\"\\nColumn names: {list(students[0].keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that everything is a string!\n",
    "first_student = students[0]\n",
    "print(f\"GPA value: {first_student['GPA']}\")\n",
    "print(f\"GPA type: {type(first_student['GPA'])}\")\n",
    "\n",
    "# You need to convert types manually\n",
    "gpa_float = float(first_student['GPA'])\n",
    "print(f\"GPA as float: {gpa_float}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data with proper type conversion\n",
    "students = []\n",
    "\n",
    "with open('lehigh_students_clean.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        student = {\n",
    "            'id': row['Student_ID'],\n",
    "            'college': row['College'],\n",
    "            'major': row['Major'],\n",
    "            'class_year': row['Class_Year'],\n",
    "            'gpa': float(row['GPA']),\n",
    "            'credits_attempted': int(row['Credits_Attempted']),\n",
    "            'credits_earned': int(row['Credits_Earned'])\n",
    "        }\n",
    "        students.append(student)\n",
    "\n",
    "print(f\"Loaded {len(students)} students with proper types\")\n",
    "print(f\"\\nFirst student: {students[0]}\")\n",
    "print(f\"GPA type: {type(students[0]['gpa'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can do calculations\n",
    "gpas = [s['gpa'] for s in students]\n",
    "avg_gpa = sum(gpas) / len(gpas)\n",
    "print(f\"Average GPA: {avg_gpa:.2f}\")\n",
    "\n",
    "# Find Dean's List students\n",
    "deans_list = [s for s in students if s['gpa'] >= 3.5]\n",
    "print(f\"Dean's List students: {len(deans_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸ› CRAWL: Exception Handling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 What Are Exceptions?\n",
    "\n",
    "When Python encounters an error during execution, it raises an **exception**. If you don't handle it, your program crashes.\n",
    "\n",
    "Common exceptions you'll encounter:\n",
    "\n",
    "| Exception | When It Occurs |\n",
    "|-----------|----------------|\n",
    "| `FileNotFoundError` | File doesn't exist |\n",
    "| `ValueError` | Can't convert value (e.g., `int('abc')`) |\n",
    "| `KeyError` | Dictionary key doesn't exist |\n",
    "| `IndexError` | List index out of range |\n",
    "| `TypeError` | Wrong type for operation |\n",
    "| `ZeroDivisionError` | Division by zero |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will crash - uncomment to see\n",
    "# file = open('nonexistent_file.csv', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will crash - uncomment to see\n",
    "# gpa = float('N/A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will crash - uncomment to see\n",
    "# student = {'id': 'LU001'}\n",
    "# print(student['gpa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 The `try/except` Block\n",
    "\n",
    "Use `try/except` to catch exceptions and handle them gracefully instead of crashing.\n",
    "\n",
    "```python\n",
    "try:\n",
    "    # Code that might raise an exception\n",
    "except ExceptionType:\n",
    "    # Code to run if that exception occurs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle file not found\n",
    "try:\n",
    "    with open('nonexistent_file.csv', 'r') as file:\n",
    "        content = file.read()\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file was not found.\")\n",
    "    print(\"Please check the file path and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle conversion errors\n",
    "gpa_values = ['3.41', '3.55', 'N/A', '3.90', '', '2.85']\n",
    "\n",
    "valid_gpas = []\n",
    "invalid_count = 0\n",
    "\n",
    "for value in gpa_values:\n",
    "    try:\n",
    "        gpa = float(value)\n",
    "        valid_gpas.append(gpa)\n",
    "    except ValueError:\n",
    "        invalid_count += 1\n",
    "        print(f\"Could not convert '{value}' to float\")\n",
    "\n",
    "print(f\"\\nValid GPAs: {valid_gpas}\")\n",
    "print(f\"Invalid values: {invalid_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catch multiple exception types\n",
    "def get_student_gpa(students, student_id):\n",
    "    \"\"\"Look up a student's GPA by ID.\"\"\"\n",
    "    try:\n",
    "        # Find the student\n",
    "        for student in students:\n",
    "            if student['id'] == student_id:\n",
    "                return float(student['gpa'])\n",
    "        raise KeyError(f\"Student {student_id} not found\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Error converting GPA: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with sample data\n",
    "sample_students = [\n",
    "    {'id': 'LU001', 'gpa': '3.41'},\n",
    "    {'id': 'LU002', 'gpa': 'N/A'},\n",
    "]\n",
    "\n",
    "print(get_student_gpa(sample_students, 'LU001'))\n",
    "print(get_student_gpa(sample_students, 'LU002'))\n",
    "print(get_student_gpa(sample_students, 'LU999'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the exception details\n",
    "try:\n",
    "    result = 10 / 0\n",
    "except ZeroDivisionError as e:\n",
    "    print(f\"Exception type: {type(e).__name__}\")\n",
    "    print(f\"Exception message: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catch any exception (use sparingly - you usually want specific types)\n",
    "try:\n",
    "    # Some risky operation\n",
    "    value = int('abc')\n",
    "except Exception as e:\n",
    "    print(f\"Something went wrong: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 The `else` and `finally` Clauses\n",
    "\n",
    "The full `try` statement can have four parts:\n",
    "\n",
    "```python\n",
    "try:\n",
    "    # Code that might fail\n",
    "except SomeError:\n",
    "    # Handle the error\n",
    "else:\n",
    "    # Runs only if NO exception occurred\n",
    "finally:\n",
    "    # ALWAYS runs, whether exception occurred or not\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    \"\"\"Safely divide two numbers.\"\"\"\n",
    "    try:\n",
    "        result = a / b\n",
    "    except ZeroDivisionError:\n",
    "        print(\"Cannot divide by zero!\")\n",
    "        return None\n",
    "    else:\n",
    "        print(f\"Division successful: {a}/{b} = {result}\")\n",
    "        return result\n",
    "    finally:\n",
    "        print(\"Division attempt complete.\\n\")\n",
    "\n",
    "safe_divide(10, 2)\n",
    "safe_divide(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally is useful for cleanup\n",
    "def process_file(filename):\n",
    "    \"\"\"Process a file and always report when done.\"\"\"\n",
    "    file = None\n",
    "    try:\n",
    "        file = open(filename, 'r')\n",
    "        content = file.read()\n",
    "        # Process the content...\n",
    "        print(f\"Processed {len(content)} characters\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filename} not found\")\n",
    "    finally:\n",
    "        if file:\n",
    "            file.close()\n",
    "            print(\"File closed\")\n",
    "        print(\"Processing complete\\n\")\n",
    "\n",
    "process_file('sample_students.txt')\n",
    "process_file('nonexistent.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** When using `with` statements, you rarely need `finally` for file cleanup because `with` handles that automatically. But `finally` is still useful for other cleanup tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ› CRAWL Practice Problems\n",
    "\n",
    "Complete these problems without any AI assistance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.1: Basic File I/O\n",
    "1. Create a file called `colleges.txt` containing the five Lehigh colleges, one per line\n",
    "2. Read the file back and print each college with a number (1. College of Business, etc.)\n",
    "3. Append \"Graduate Programs\" to the file\n",
    "4. Read and display the updated file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.2: CSV Reading\n",
    "Load the clean Lehigh student dataset and:\n",
    "1. Count how many students are in each college\n",
    "2. Find the average GPA (remember to convert from string to float)\n",
    "3. List all unique majors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.3: CSV Writing\n",
    "Filter the Lehigh dataset to include only students with GPA >= 3.5 and write them to a new file called `deans_list.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.4: Exception Handling\n",
    "Write a function `safe_gpa_convert(value)` that:\n",
    "- Takes a string value\n",
    "- Returns the float if conversion succeeds\n",
    "- Returns None if conversion fails\n",
    "- Prints an informative message for failures\n",
    "\n",
    "Test with: '3.41', '', 'N/A', '3.5 ', '-1.0', '5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.5: Predict the Output\n",
    "What happens in each case? Predict first, then run.\n",
    "\n",
    "```python\n",
    "a) \n",
    "try:\n",
    "    x = int('hello')\n",
    "    print('Success')\n",
    "except ValueError:\n",
    "    print('Failed')\n",
    "\n",
    "b)\n",
    "try:\n",
    "    x = 10 / 2\n",
    "except ZeroDivisionError:\n",
    "    print('Division error')\n",
    "else:\n",
    "    print(f'Result: {x}')\n",
    "\n",
    "c)\n",
    "try:\n",
    "    x = int('5')\n",
    "except ValueError:\n",
    "    x = 0\n",
    "finally:\n",
    "    print(f'x = {x}')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸš¶ WALK: Advanced File Handling and Data Validation\n",
    "\n",
    "**Rules for this section:**\n",
    "- You may use AI tools to **explain** concepts and errors\n",
    "- You must **write all code yourself**\n",
    "- Good prompts: \"What does this encoding error mean?\" or \"How do I handle different date formats?\"\n",
    "- Bad prompts: \"Write code to clean my CSV file\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 File Encodings\n",
    "\n",
    "Text files use **encodings** to convert bytes to characters. The most common encodings are:\n",
    "\n",
    "| Encoding | Description | When to Use |\n",
    "|----------|-------------|-------------|\n",
    "| UTF-8 | Universal, handles all languages | Default choice, most modern files |\n",
    "| Latin-1 (ISO-8859-1) | Western European characters | Older Windows files |\n",
    "| cp1252 | Windows Western | Excel exports |\n",
    "\n",
    "When you get a `UnicodeDecodeError`, the file probably uses a different encoding than Python expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify encoding explicitly (best practice)\n",
    "with open('sample_students.txt', 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to try multiple encodings\n",
    "def read_file_with_fallback(filename):\n",
    "    \"\"\"Try to read a file with multiple encodings.\"\"\"\n",
    "    encodings = ['utf-8', 'latin-1', 'cp1252']\n",
    "    \n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            with open(filename, 'r', encoding=encoding) as file:\n",
    "                content = file.read()\n",
    "            print(f\"Successfully read with {encoding}\")\n",
    "            return content\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"{encoding} failed, trying next...\")\n",
    "    \n",
    "    raise ValueError(f\"Could not read {filename} with any known encoding\")\n",
    "\n",
    "# Test it\n",
    "content = read_file_with_fallback('sample_students.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Raising Exceptions for Data Validation\n",
    "\n",
    "You can raise your own exceptions when data doesn't meet your requirements. This is crucial for data quality.\n",
    "\n",
    "```python\n",
    "raise ExceptionType(\"Error message\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_gpa(gpa):\n",
    "    \"\"\"Validate that GPA is within valid range.\"\"\"\n",
    "    if gpa < 0:\n",
    "        raise ValueError(f\"GPA cannot be negative: {gpa}\")\n",
    "    if gpa > 4.0:\n",
    "        raise ValueError(f\"GPA cannot exceed 4.0: {gpa}\")\n",
    "    return True\n",
    "\n",
    "# Test\n",
    "print(validate_gpa(3.5))  # OK\n",
    "\n",
    "try:\n",
    "    validate_gpa(5.0)  # Invalid\n",
    "except ValueError as e:\n",
    "    print(f\"Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_student_record(record):\n",
    "    \"\"\"Validate a student record dictionary.\"\"\"\n",
    "    required_fields = ['id', 'gpa', 'credits_attempted', 'credits_earned']\n",
    "    \n",
    "    # Check for missing fields\n",
    "    for field in required_fields:\n",
    "        if field not in record:\n",
    "            raise KeyError(f\"Missing required field: {field}\")\n",
    "    \n",
    "    # Validate GPA\n",
    "    gpa = record['gpa']\n",
    "    if not (0 <= gpa <= 4.0):\n",
    "        raise ValueError(f\"Invalid GPA {gpa} for student {record['id']}\")\n",
    "    \n",
    "    # Validate credits relationship\n",
    "    if record['credits_earned'] > record['credits_attempted']:\n",
    "        raise ValueError(f\"Credits earned ({record['credits_earned']}) > attempted ({record['credits_attempted']})\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Test with valid record\n",
    "good_record = {'id': 'LU001', 'gpa': 3.5, 'credits_attempted': 100, 'credits_earned': 95}\n",
    "print(f\"Valid record: {validate_student_record(good_record)}\")\n",
    "\n",
    "# Test with invalid record\n",
    "bad_record = {'id': 'LU002', 'gpa': 5.0, 'credits_attempted': 100, 'credits_earned': 95}\n",
    "try:\n",
    "    validate_student_record(bad_record)\n",
    "except ValueError as e:\n",
    "    print(f\"Invalid record: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10 Building a Data Loading Function\n",
    "\n",
    "Let's combine everything into a robust function that can handle the messy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_student_data(filename, validate=True, skip_invalid=True):\n",
    "    \"\"\"\n",
    "    Load student data from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        filename: Path to the CSV file\n",
    "        validate: Whether to validate each record\n",
    "        skip_invalid: If True, skip invalid records; if False, raise exception\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (valid_records, error_log)\n",
    "    \"\"\"\n",
    "    valid_records = []\n",
    "    error_log = []\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            \n",
    "            for row_num, row in enumerate(reader, start=2):  # Start at 2 (1 is header)\n",
    "                try:\n",
    "                    # Convert types\n",
    "                    record = {\n",
    "                        'id': row['Student_ID'],\n",
    "                        'college': row['College'].strip(),  # Strip whitespace\n",
    "                        'major': row['Major'].strip(),\n",
    "                        'class_year': row['Class_Year'].strip(),\n",
    "                        'gpa': float(row['GPA']) if row['GPA'].strip() else None,\n",
    "                        'credits_attempted': int(row['Credits_Attempted']) if row['Credits_Attempted'].strip() else None,\n",
    "                        'credits_earned': int(row['Credits_Earned']) if row['Credits_Earned'].strip() else None\n",
    "                    }\n",
    "                    \n",
    "                    if validate and record['gpa'] is not None:\n",
    "                        if not (0 <= record['gpa'] <= 4.0):\n",
    "                            raise ValueError(f\"Invalid GPA: {record['gpa']}\")\n",
    "                    \n",
    "                    valid_records.append(record)\n",
    "                    \n",
    "                except (ValueError, KeyError) as e:\n",
    "                    error_msg = f\"Row {row_num}: {e}\"\n",
    "                    error_log.append(error_msg)\n",
    "                    \n",
    "                    if not skip_invalid:\n",
    "                        raise\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Could not find file: {filename}\")\n",
    "    \n",
    "    return valid_records, error_log\n",
    "\n",
    "# Test with the clean dataset\n",
    "students, errors = load_student_data('lehigh_students_clean.csv')\n",
    "print(f\"Loaded {len(students)} valid records\")\n",
    "print(f\"Errors encountered: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸš¶ WALK Practice Problems\n",
    "\n",
    "Use AI to help you understand concepts and errors, but write all code yourself.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.6: Robust Data Loader\n",
    "Enhance the `load_student_data` function to also:\n",
    "1. Track which specific fields had errors (missing, invalid type, out of range)\n",
    "2. Return statistics about the loading process (total rows, valid rows, rows with each error type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.7: Data Validation Suite\n",
    "Write a set of validation functions for the Lehigh dataset:\n",
    "1. `validate_college(college)` - Check if college is one of the 5 valid options\n",
    "2. `validate_class_year(year)` - Check if class year is valid\n",
    "3. `validate_credits(attempted, earned)` - Check if credits relationship is valid\n",
    "4. `validate_record(record)` - Run all validations on a record\n",
    "\n",
    "Each should raise a descriptive exception on failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.8: Load and Analyze the Messy Dataset\n",
    "Load `lehigh_students_messy.csv` and report:\n",
    "1. How many records failed to load?\n",
    "2. What were the most common errors?\n",
    "3. How many unique college names exist (before standardization)?\n",
    "\n",
    "If you get stuck on specific errors, ask AI to explain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5.9: Debug These Errors\n",
    "Fix these code snippets. Use AI to understand the errors if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 1: Fix this file reading code\n",
    "with open('sample_students.txt') as file:\n",
    "    for line in file:\n",
    "        print(line)\n",
    "print(file.read())  # Why does this fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 2: This doesn't catch the error. Why?\n",
    "try:\n",
    "    x = int('3.14')  # Should work, right?\n",
    "except TypeError:\n",
    "    print(\"Type error caught\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error 3: Fix the CSV writing\n",
    "data = [{'name': 'Alice', 'gpa': 3.5}]\n",
    "with open('output.csv', 'w') as file:\n",
    "    writer = csv.DictWriter(file)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ðŸš€ RUN: Data Cleaning Pipeline\n",
    "\n",
    "**Rules for this section:**\n",
    "- Full AI collaboration is encouraged\n",
    "- Document your process\n",
    "- You must understand and be able to explain every line\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter Project: Clean the Messy Lehigh Dataset\n",
    "\n",
    "This is the culminating project for Weeks 1-3. You'll apply everything you've learned to transform the messy dataset into a clean, analyzable version.\n",
    "\n",
    "### The Messy Dataset Issues\n",
    "\n",
    "The file `lehigh_students_messy.csv` contains 605 records with these problems:\n",
    "\n",
    "| Issue | Count | Example |\n",
    "|-------|-------|--------|\n",
    "| Inconsistent college names | 28 variations | \"COB\", \"Business\", \"college of business\" |\n",
    "| Inconsistent class years | 23 variations | \"Fr\", \"Freshman\", \"first year\" |\n",
    "| Missing GPA | ~35 records | Empty cells |\n",
    "| Missing credits | ~36 records | Empty cells |\n",
    "| Extra whitespace | ~151 records | \"  Engineering  \" |\n",
    "| Typos in majors | ~30 records | \"Computer Sceince\", \"Finace\" |\n",
    "| Invalid GPA values | ~8 records | GPA > 4.0 |\n",
    "| Duplicate records | 5 records | Same Student_ID twice |\n",
    "| Inconsistent date formats | 3+ formats | Mixed date styles |\n",
    "\n",
    "### Requirements\n",
    "\n",
    "Build a data cleaning pipeline that:\n",
    "\n",
    "1. **Loads the messy data** with proper error handling\n",
    "2. **Standardizes college names** to the 5 official names\n",
    "3. **Standardizes class years** to consistent format\n",
    "4. **Strips whitespace** from all text fields\n",
    "5. **Handles missing values** (document your strategy)\n",
    "6. **Fixes typos** in major names\n",
    "7. **Validates GPA** and flags/corrects invalid values\n",
    "8. **Detects and removes duplicates** (keep the first occurrence)\n",
    "9. **Writes the cleaned data** to `lehigh_students_cleaned.csv`\n",
    "10. **Generates a cleaning report** showing what was fixed\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "1. A cleaned CSV file with 600 valid, standardized records\n",
    "2. A cleaning report showing:\n",
    "   - How many records were affected by each issue\n",
    "   - What standardization rules you applied\n",
    "   - How you handled missing values and why\n",
    "   - Any records that were dropped and why\n",
    "3. Documented code explaining your process\n",
    "\n",
    "### AI Collaboration Tips\n",
    "\n",
    "Good prompts:\n",
    "- \"What's the best way to create a mapping dictionary for standardizing names?\"\n",
    "- \"How can I detect near-duplicate strings that might be typos?\"\n",
    "- \"Explain fuzzy string matching for finding similar major names\"\n",
    "\n",
    "Avoid:\n",
    "- \"Clean this dataset for me\"\n",
    "- \"Write a data cleaning script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING PIPELINE\n",
    "#\n",
    "# AI Collaboration Log:\n",
    "# - Prompts used:\n",
    "# - Key insights:\n",
    "# - My modifications:\n",
    "\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# ============================================\n",
    "# CONFIGURATION: Standardization Mappings\n",
    "# ============================================\n",
    "\n",
    "# Official college names\n",
    "VALID_COLLEGES = {\n",
    "    \"College of Business\",\n",
    "    \"P.C. Rossin College of Engineering\",\n",
    "    \"College of Arts and Sciences\",\n",
    "    \"College of Health\",\n",
    "    \"College of Education\"\n",
    "}\n",
    "\n",
    "# Mapping from variations to standard names\n",
    "COLLEGE_MAP = {\n",
    "    # Business variations\n",
    "    'cob': 'College of Business',\n",
    "    'business': 'College of Business',\n",
    "    'college of business': 'College of Business',\n",
    "    'buisness': 'College of Business',\n",
    "    # Add more mappings as you discover them...\n",
    "}\n",
    "\n",
    "# Add your class year mappings\n",
    "CLASS_YEAR_MAP = {\n",
    "    # First Year variations\n",
    "    'fr': 'First Year',\n",
    "    'freshman': 'First Year',\n",
    "    'first year': 'First Year',\n",
    "    '1st year': 'First Year',\n",
    "    # Add more...\n",
    "}\n",
    "\n",
    "# Add your major typo fixes\n",
    "MAJOR_FIXES = {\n",
    "    'computer sceince': 'Computer Science',\n",
    "    'finace': 'Finance',\n",
    "    # Add more...\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# CLEANING FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def standardize_college(college):\n",
    "    \"\"\"Standardize college name to official format.\"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def standardize_class_year(year):\n",
    "    \"\"\"Standardize class year to official format.\"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def fix_major_typo(major):\n",
    "    \"\"\"Fix known typos in major names.\"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def clean_gpa(gpa_str):\n",
    "    \"\"\"Convert GPA string to float, handling errors.\"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def clean_record(row):\n",
    "    \"\"\"\n",
    "    Clean a single student record.\n",
    "    Returns (cleaned_record, issues_found)\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# ============================================\n",
    "# MAIN PIPELINE\n",
    "# ============================================\n",
    "\n",
    "def run_cleaning_pipeline(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Run the complete data cleaning pipeline.\n",
    "    \n",
    "    Returns a report dictionary with statistics.\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# ============================================\n",
    "# RUN THE PIPELINE\n",
    "# ============================================\n",
    "\n",
    "# report = run_cleaning_pipeline('lehigh_students_messy.csv', 'lehigh_students_cleaned.csv')\n",
    "# print_cleaning_report(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Report Template\n",
    "\n",
    "After running your pipeline, fill in this report:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "DATA CLEANING REPORT\n",
    "====================\n",
    "\n",
    "Input file: lehigh_students_messy.csv\n",
    "Output file: lehigh_students_cleaned.csv\n",
    "\n",
    "SUMMARY\n",
    "-------\n",
    "Records in input: ___\n",
    "Records in output: ___\n",
    "Records dropped: ___\n",
    "\n",
    "ISSUES FIXED\n",
    "------------\n",
    "College names standardized: ___ records\n",
    "Class years standardized: ___ records  \n",
    "Whitespace stripped: ___ records\n",
    "Major typos fixed: ___ records\n",
    "Duplicates removed: ___ records\n",
    "\n",
    "MISSING VALUES\n",
    "--------------\n",
    "Records with missing GPA: ___\n",
    "Records with missing credits: ___\n",
    "Strategy used: [describe your approach]\n",
    "\n",
    "INVALID VALUES\n",
    "--------------\n",
    "Invalid GPA values found: ___\n",
    "Strategy used: [describe your approach]\n",
    "\n",
    "STANDARDIZATION MAPPINGS\n",
    "------------------------\n",
    "College variations found: [list them]\n",
    "Class year variations found: [list them]\n",
    "Major typos found: [list them]\n",
    "\n",
    "QUALITY VERIFICATION\n",
    "--------------------\n",
    "Unique colleges in output: ___ (should be 5)\n",
    "Unique class years in output: ___ (should be 5)\n",
    "GPA range in output: ___ to ___ (should be 0.0-4.0)\n",
    "All Student_IDs unique: Yes/No\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Reflection\n",
    "\n",
    "1. Which data quality issue was hardest to handle? Why?\n",
    "2. What decisions did you make about missing values? Defend your choice.\n",
    "3. How would you handle this differently with pandas (which you'll learn next week)?\n",
    "4. What additional validations would you add for production use?\n",
    "5. How did AI help (or not help) with this project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your reflection here:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Midterm Preparation\n",
    "\n",
    "The midterm exam covers Chapters 1-5. Here's what you need to know **without AI assistance**:\n",
    "\n",
    "## From Chapter 5 (File I/O and Exceptions)\n",
    "\n",
    "### Must Know (CRAWL)\n",
    "- [ ] Open files with `open()` and different modes ('r', 'w', 'a')\n",
    "- [ ] Use `with` statements for safe file handling\n",
    "- [ ] Read files: `read()`, `readline()`, `readlines()`\n",
    "- [ ] Write to files with `write()`\n",
    "- [ ] Use `csv.reader` and `csv.DictReader`\n",
    "- [ ] Write `try/except` blocks for common exceptions\n",
    "- [ ] Know when `FileNotFoundError`, `ValueError`, `KeyError` occur\n",
    "\n",
    "### Should Know (WALK)\n",
    "- [ ] Handle multiple exception types\n",
    "- [ ] Use `else` and `finally` clauses\n",
    "- [ ] Raise your own exceptions with `raise`\n",
    "- [ ] Work with file encodings\n",
    "\n",
    "## Common Exam Question Types\n",
    "\n",
    "1. **Code output prediction:** Given code with file operations or try/except, predict what happens\n",
    "2. **Error identification:** Identify what's wrong with file handling code\n",
    "3. **Code completion:** Fill in blanks to make file I/O code work\n",
    "4. **Short answer:** Explain the difference between 'r', 'w', 'a' modes\n",
    "5. **Practical:** Write code to load a CSV and calculate something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 1: What does this print?\n",
    "\n",
    "try:\n",
    "    x = int('hello')\n",
    "    print('A')\n",
    "except ValueError:\n",
    "    print('B')\n",
    "else:\n",
    "    print('C')\n",
    "finally:\n",
    "    print('D')\n",
    "\n",
    "# Your prediction: ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 2: What does this print?\n",
    "\n",
    "try:\n",
    "    x = int('5')\n",
    "    print('A')\n",
    "except ValueError:\n",
    "    print('B')\n",
    "else:\n",
    "    print('C')\n",
    "finally:\n",
    "    print('D')\n",
    "\n",
    "# Your prediction: ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 3: What's wrong with this code?\n",
    "\n",
    "file = open('data.txt', 'r')\n",
    "data = file.read()\n",
    "# process data...\n",
    "# What's missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice 4: Fill in the blanks\n",
    "\n",
    "# Read a CSV file and print each row\n",
    "import ___\n",
    "\n",
    "___ open('students.csv', 'r') as file:\n",
    "    reader = csv.___(file)\n",
    "    for ___ in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Accountability Check\n",
    "\n",
    "## ðŸ› CRAWL (Must do without AI)\n",
    "- [ ] Open, read, and close files with `open()`\n",
    "- [ ] Use `with` statements for file handling\n",
    "- [ ] Explain the difference between 'r', 'w', 'a' modes\n",
    "- [ ] Read files with `read()`, `readline()`, `readlines()`\n",
    "- [ ] Parse CSV files with `csv.reader` and `csv.DictReader`\n",
    "- [ ] Write `try/except` blocks to handle specific exceptions\n",
    "- [ ] Know which exceptions occur in common situations\n",
    "\n",
    "## ðŸš¶ WALK (AI to learn, write code yourself)\n",
    "- [ ] Handle multiple exception types in one block\n",
    "- [ ] Use `else` and `finally` appropriately\n",
    "- [ ] Raise exceptions for data validation\n",
    "- [ ] Work with file encodings (UTF-8, Latin-1)\n",
    "- [ ] Build robust data loading functions\n",
    "\n",
    "## ðŸš€ RUN (AI-assisted, must understand)\n",
    "- [ ] Build a complete data cleaning pipeline\n",
    "- [ ] Handle multiple data quality issues systematically\n",
    "- [ ] Document cleaning decisions and their rationale\n",
    "- [ ] Generate cleaning reports with statistics\n",
    "\n",
    "**Review CRAWL material before the midterm. You cannot use AI on the exam.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "After the midterm, you'll enter the data analysis phase:\n",
    "\n",
    "**Week 4: NumPy**\n",
    "- Numerical arrays for fast computation\n",
    "- Statistical operations\n",
    "- The foundation of pandas\n",
    "\n",
    "**Week 5: Pandas**\n",
    "- DataFrames for tabular data (think: Excel on steroids)\n",
    "- Everything you did in this chapter's project, but in one line of code\n",
    "- Group by, merge, pivot operations\n",
    "\n",
    "**Week 6: Visualization**\n",
    "- Matplotlib and Seaborn\n",
    "- Turning data into insights\n",
    "- Final project\n",
    "\n",
    "The cleaned dataset you produced in this chapter will be your data for the rest of the course. Good luck on the midterm!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
